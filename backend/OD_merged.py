import os
import pandas as pd
import sqlite3
import torch
import clip
from ultralytics import YOLO
from PIL import Image
import numpy as np
from torchvision import transforms
from dotenv import load_dotenv

from langchain_community.document_loaders import DataFrameLoader
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.retrievers import EnsembleRetriever, BM25Retriever
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.memory import ConversationBufferMemory
from collections import Counter

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"  # OpenMP ì¶©ëŒ ë°©ì§€ ì„¤ì •

# âœ… YOLO ë° CLIP ëª¨ë¸ ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
yolo_model_path = os.path.join(BASE_DIR, "OD", "YOLO", "detect", "workspace", "runs", "detect", "train3", "weights", "best.pt")
yolo_model = YOLO(yolo_model_path)

# CLIP ëª¨ë¸ ë¡œë“œ
clip_model, preprocess = clip.load("ViT-B/32", device=device)



# âœ… YOLO ê°ì§€ í´ë˜ìŠ¤ì˜ í•œê¸€ ë³€í™˜ ë”•ì…”ë„ˆë¦¬ (ëˆ„ë½ëœ í•­ëª© ì¶”ê°€)
ingredient_translations = {
    "Potato": "ê°ì",
    "egg": "ë‹¬ê±€",
    "cucumber": "ì˜¤ì´",
    "green chilies": "ì²­ì–‘ê³ ì¶”",
    "spring onion": "ìª½íŒŒ",
    "pear": "ë°°",
    "Capsicum": "í”¼ë§",
    "Green Peas": "ì™„ë‘ì½©",
    "tomato": "í† ë§ˆí† ",
    "green beans": "ê½ˆë¦¬ê³ ì¶”",
    "ham": "í–„",
    "apple": "ì‚¬ê³¼",
    "Onion": "ì–‘íŒŒ",
    "brinjal": "ê°€ì§€",
    "lemon": "ë ˆëª¬",
    "chocolate": "ì´ˆì½œë¦¿",
    "Bitter melon": "ì—¬ì£¼",
    "goat_cheese": "ì—¼ì†Œ ì¹˜ì¦ˆ",
    "papaya": "íŒŒíŒŒì•¼",
    "heavy_cream": "ìƒí¬ë¦¼",
    "flour": "ë°€ê°€ë£¨",
    "strawberry": "ë”¸ê¸°",
    "beet": "ë¹„íŠ¸",
    "half carrot": "ë°˜ ê°œì˜ ë‹¹ê·¼",
    "strawberries": "ë”¸ê¸°",
    "cauliflower": "ì½œë¦¬í”Œë¼ì›Œ",
    "zucchini": "ì£¼í‚¤ë‹ˆ",
    "swiss yoghurt": "ìŠ¤ìœ„ìŠ¤ ìš”êµ¬ë¥´íŠ¸",
    "chilli": "ê³ ì¶”",
    "peas": "ì™„ë‘ì½©",
    "Sapodilla": "ì‚¬í¬ë”œë¼",
    "corn": "ì˜¥ìˆ˜ìˆ˜",
    "orange": "ì˜¤ë Œì§€",
    "butter": "ë²„í„°",
    "olive": "ì˜¬ë¦¬ë¸Œ",
    "peach": "ë³µìˆ­ì•„",
    "jalapeno": "í• ë¼í”¼ë‡¨",
    "scarletgourds": "ë¶‰ì€ ë°•",
    "sauce": "ì†ŒìŠ¤",
    "redonion": "ì ì–‘íŒŒ",
    "chillies": "ê³ ì¶”",
    "chicken": "ë‹­ê³ ê¸°",
    "pumpkin": "í˜¸ë°•",
    "Green Chili": "í’‹ê³ ì¶”",
    "mineral water": "ìƒìˆ˜",
    "shrimp": "ìƒˆìš°",
    "mango": "ë§ê³ ",
    "half onion": "ë°˜ ê°œì˜ ì–‘íŒŒ",
    "Ginger": "ìƒê°•",
    "raddish": "ë¬´",
    "basil": "ë°”ì§ˆ",
    "sweet potato": "ê³ êµ¬ë§ˆ",
    "beef": "ì†Œê³ ê¸°",
    "chicken_breast": "ë‹­ê°€ìŠ´ì‚´",
    "beans": "ì½©",
    "charger": "ì¶©ì „ê¸°",
    "swiss butter": "ìŠ¤ìœ„ìŠ¤ ë²„í„°",
    "red grapes": "ì í¬ë„",
    "milk": "ìš°ìœ ",
    "parsley": "íŒŒìŠ¬ë¦¬",
    "watermelon": "ìˆ˜ë°•",
    "Lady finger": "ì˜¤í¬ë¼",
    "bell_pepper": "íŒŒí”„ë¦¬ì¹´",
    "sausage": "ì†Œì‹œì§€",
    "beetroot": "ë¹„íŠ¸",
    "Brinjal": "ê°€ì§€",
    "sweet_potato": "ê³ êµ¬ë§ˆ",
    "mushroom": "ë²„ì„¯",
    "Cluster bean": "í´ëŸ¬ìŠ¤í„° ì½©",
    "bottle": "ë³‘",
    "Curry Leaf": "ì»¤ë¦¬ ì",
    "potato": "ê°ì",
    "Hyacinth Beans": "íˆì•„ì‹ ìŠ¤ ì½©",
    "Cabbage": "ì–‘ë°°ì¶”",
    "grape": "í¬ë„",
    "peppers": "ê³ ì¶”",
    "shallot": "ìƒ¬ë¡¯",
    "ginger": "ìƒê°•",
    "bittergourd": "ì—¬ì£¼",
    "sugar": "ì„¤íƒ•",
    "eggplant": "ê°€ì§€",
    "cheese": "ì¹˜ì¦ˆ",
    "kiwi": "í‚¤ìœ„",
    "fig": "ë¬´í™”ê³¼",
    "Calabash": "ì¡°ë¡±ë°•",
    "Tomato": "í† ë§ˆí† ",
    "Cauliflower": "ì½œë¦¬í”Œë¼ì›Œ",
    "swiss jam": "ìŠ¤ìœ„ìŠ¤ ì¼",
    "Garlic": "ë§ˆëŠ˜",
    "courgettes": "ì• í˜¸ë°•",
    "eggs": "ë‹¬ê±€",
    "dates": "ëŒ€ì¶”",
    "broccoli": "ë¸Œë¡œì½œë¦¬",
    "mushrooms": "ë²„ì„¯",
    "ground_beef": "ë‹¤ì§„ ì†Œê³ ê¸°",
    "pineapple": "íŒŒì¸ì• í”Œ",
    "pomogranate": "ì„ë¥˜",
    "aubergine": "ê°€ì§€",
    "blueberries": "ë¸”ë£¨ë² ë¦¬",
    "carrot": "ë‹¹ê·¼",
    "red onion": "ì ì–‘íŒŒ",
    "bottlegourd": "í˜¸ë¦¬ë³‘ë°•",
    "haft-cabbage": "ë°˜ ê°œì˜ ì–‘ë°°ì¶”",
    "lettuce": "ìƒì¶”",
    "green_beans": "ê½ˆë¦¬ê³ ì¶”",
    "capsicum": "í”¼ë§",
    "garlic": "ë§ˆëŠ˜",
    "onion": "ì–‘íŒŒ",
    "cabbage": "ì–‘ë°°ì¶”",
    "bell pepper": "íŒŒí”„ë¦¬ì¹´",
    "spounggourd": "ìˆ˜ì„¸ë¯¸ì˜¤ì´",
    "spinach": "ì‹œê¸ˆì¹˜",
    "lime": "ë¼ì„",
    "Sponge Gourd": "ìˆ˜ì„¸ë¯¸ ì˜¤ì´",
    "banana": "ë°”ë‚˜ë‚˜",
    "bread": "ë¹µ",
    "asparagus": "ì•„ìŠ¤íŒŒë¼ê±°ìŠ¤",
    "coriander": "ê³ ìˆ˜"
}

# âœ… CLIP ì‚¬ì „ ì •ì˜ëœ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
possible_labels = [
        # âœ… ì±„ì†Œ
        "ì–‘íŒŒ (Onion)", "ëŒ€íŒŒ (Green Onion)", "ìª½íŒŒ (Spring Onion)", "ë§ˆëŠ˜ (Garlic)", "ë°°ì¶” (Napa Cabbage)", 
        "ì–‘ë°°ì¶” (Cabbage)", "ê¹»ì (Perilla Leaf)", "ì‹œê¸ˆì¹˜ (Spinach)", 
        "ë¶€ì¶” (Chives)", "ë¯¸ë‚˜ë¦¬ (Water Parsley)", "ì‘¥ê°“ (Crown Daisy)", "ì²­ê²½ì±„ (Bok Choy)", 
        "ë‹¹ê·¼ (Carrot)", "ë¬´ (Radish)", "ê°ì (Potato)", "ê³ êµ¬ë§ˆ (Sweet Potato)", "í˜¸ë°• (Pumpkin)",
        "ê°€ì§€ (Eggplant)", "ì˜¤ì´ (Cucumber)", "í”¼ë§ (Bell Pepper)", "íŒŒí”„ë¦¬ì¹´ (Capsicum)", "ì½©ë‚˜ë¬¼ (Bean Sprouts)", "í™ê³ ì¶” (Red Pepper)",

        # âœ… ë²„ì„¯ë¥˜
        "ë²„ì„¯ (Mushroom)", "ìƒˆì†¡ì´ë²„ì„¯ (King Oyster Mushroom)", "í‘œê³ ë²„ì„¯ (Shiitake Mushroom)", 
        "íŒ½ì´ë²„ì„¯ (Enoki Mushroom)", "ëŠíƒ€ë¦¬ë²„ì„¯ (Oyster Mushroom)", 

        # âœ… ê³¼ì¼
        "ì‚¬ê³¼ (Apple)", "ë°° (Pear)", "ê·¤ (Tangerine)", "ì˜¤ë Œì§€ (Orange)", "ë ˆëª¬ (Lemon)", 
        "ìëª½ (Grapefruit)", "ë°”ë‚˜ë‚˜ (Banana)", "í¬ë„ (Grape)", "ìˆ˜ë°• (Watermelon)", 
        "ë”¸ê¸° (Strawberry)", "ë¸”ë£¨ë² ë¦¬ (Blueberry)", "ì²´ë¦¬ (Cherry)", "ë§ê³  (Mango)", 
        "íŒŒì¸ì• í”Œ (Pineapple)", "í‚¤ìœ„ (Kiwi)", "ë³µìˆ­ì•„ (Peach)", "ìë‘ (Plum)", 

        # âœ… ìœ¡ë¥˜
        "ì†Œê³ ê¸° (Beef)", "ë¼ì§€ê³ ê¸° (Pork)", "ë‹­ê³ ê¸° (Chicken)", "ì–‘ê³ ê¸° (Lamb)", 
        "ì‚¼ê²¹ì‚´ (Pork Belly)", "ëª©ì‚´ (Pork Shoulder)", "ê°ˆë¹„ (Ribs)", "ì•ˆì‹¬ (Tenderloin)", 
        "ë“±ì‹¬ (Sirloin)", "ë‹­ë‹¤ë¦¬ì‚´ (Chicken Thigh)", "ë‹­ë‚ ê°œ (Chicken Wing)", 

        # âœ… í•´ì‚°ë¬¼
        "ìƒˆìš° (Shrimp)", "ì˜¤ì§•ì–´ (Squid)", "ë¬¸ì–´ (Octopus)", "ë‚™ì§€ (Small Octopus)", 
        "ê½ƒê²Œ (Blue Crab)", "ëŒ€ê²Œ (Snow Crab)", "ë°”ì§€ë½ (Clam)", "í™í•© (Mussel)", 
        "ì „ë³µ (Abalone)", "êµ´ (Oyster)", "ê³ ë“±ì–´ (Mackerel)", "ê°ˆì¹˜ (Hairtail)", 
        "ì—°ì–´ (Salmon)", "ì°¸ì¹˜ (Tuna)", "ê´‘ì–´ (Flounder)", "ì¡°ê¸° (Croaker)",

        # âœ… ìœ ì œí’ˆ
        "ìš°ìœ  (Milk)", "ì¹˜ì¦ˆ (Cheese)", "ìš”ê±°íŠ¸ (Yogurt)", "ë²„í„° (Butter)", "ìƒí¬ë¦¼ (Whipping Cream)", "í¬ë¦¼ì¹˜ì¦ˆ (Cream Cheese)",
        "ì—°ìœ  (Condensed Milk)", "ì•„ì´ìŠ¤í¬ë¦¼ (Ice Cream)",

        # âœ… ê³¡ë¥˜ ë° ê²¬ê³¼ë¥˜
        "ìŒ€ (Rice)", "í˜„ë¯¸ (Brown Rice)", "ì°¹ìŒ€ (Glutinous Rice)", "ë³´ë¦¬ (Barley)", 
        "ì•„ëª¬ë“œ (Almond)", "í˜¸ë‘ (Walnut)", "ì£ (Pine Nut)", "ìºìŠˆë„› (Cashew)", "í”¼ìŠ¤íƒ€ì¹˜ì˜¤ (Pistachio)",
        "í•´ë°”ë¼ê¸°ì”¨ (Sunflower Seed)", "ì½© (Soybean)", "ê²€ì •ì½© (Black Bean)", "ë…¹ë‘ (Mung Bean)",
        "íŒ¥ (Red Bean)", "ì°¸ê¹¨ (Sesame)", "í€´ë…¸ì•„ (Quinoa)", "ì˜¥ìˆ˜ìˆ˜ (Corn)",

        # âœ… ê¸°íƒ€
        "ë‘ë¶€ (Tofu)", "ë–¡ (Rice Cake)", "ì–´ë¬µ (Fish Cake)", "ê¹€ (Seaweed)", "í•´ì´ˆ (Seaweed)", 
        "ë¼ë©´ (Instant Noodles)", "êµ­ìˆ˜ (Noodles)", "ë§Œë‘ (Dumplings)", "í”¼ì (Pizza)",
        "í–„ë²„ê±° (Hamburger)", "ìƒŒë“œìœ„ì¹˜ (Sandwich)", "ì¼€ì´í¬ (Cake)", "ì¿ í‚¤ (Cookie)", "íŒŒìŠ¤íƒ€ (Pasta)",   
]

# CLIP í† í°í™”
text_inputs = clip.tokenize(possible_labels).to(device)
text_features = clip_model.encode_text(text_inputs).detach()

# def translate_ingredients(ingredients):
#     """ YOLO ê°ì§€ í´ë˜ìŠ¤ê°€ í•œê¸€ ë³€í™˜ ë”•ì…”ë„ˆë¦¬ì— ìˆìœ¼ë©´ ë³€í™˜, ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ """
#     return [ingredient_translations.get(ing, ing) for ing in ingredients]

# âœ… ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
def detect_ingredients(image_path):
    """ YOLO + CLIPì„ í™œìš©í•œ ì‹ì¬ë£Œ ê°ì§€ """

    image = Image.open(image_path).convert("RGB")
    image_width, image_height = image.size
    results = yolo_model(image_path, conf=0.1)

    detected_ingredients = set()
    yolo_detected = False
    expand_ratio = 1.2  # YOLO ê°ì§€ ë°•ìŠ¤ í™•ì¥ ë¹„ìœ¨
    grid_size = 150  # YOLO ë¯¸ê°ì§€ ì˜ì—­ì— ëŒ€í•´ CLIPì´ ë¶„ì„í•  ê·¸ë¦¬ë“œ í¬ê¸°

    # âœ… YOLO ê°ì§€ ê°ì²´ ë¶„ì„
    for result in results:
        for box in result.boxes:
            confidence = box.conf[0].item()
            label = result.names[int(box.cls[0])]

            if confidence >= 0.4:
                print(f"âœ… YOLO ê°ì§€: {label} (ì‹ ë¢°ë„ {confidence:.2f})")
                detected_ingredients.add(label)
                yolo_detected = True
            else:
                print(f"âš ï¸ YOLO ì‹ ë¢°ë„ {confidence:.2f} (0.4 ë¯¸ë§Œ), CLIPìœ¼ë¡œ ë³´ì™„ ë¶„ì„...")

                # YOLO ê°ì§€ ë°•ìŠ¤ í¬ê¸° í™•ì¥
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                box_width = x2 - x1
                box_height = y2 - y1

                x1 = max(0, x1 - int((expand_ratio - 1) / 2 * box_width))
                y1 = max(0, y1 - int((expand_ratio - 1) / 2 * box_height))
                x2 = min(image_width, x2 + int((expand_ratio - 1) / 2 * box_width))
                y2 = min(image_height, y2 + int((expand_ratio - 1) / 2 * box_height))

                cropped_img = image.crop((x1, y1, x2, y2))

                # CLIPìœ¼ë¡œ ë³´ì™„ ë¶„ì„
                image_input = preprocess(cropped_img).unsqueeze(0).to(device)
                image_features = clip_model.encode_image(image_input).detach()
                similarity = (image_features @ text_features.T).softmax(dim=-1)

                for idx, conf in enumerate(similarity.squeeze(0).tolist()):
                    if conf >= 0.2:
                        detected_ingredients.add(possible_labels[idx])
                        print(f"âœ… CLIP ë³´ì™„ ê²°ê³¼: {possible_labels[idx]} (ìœ ì‚¬ë„ {conf:.2f})")

    # âœ… YOLOê°€ ê°ì§€í•œ ê°ì²´ê°€ ì—†ì„ ê²½ìš°, ì „ì²´ ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œë¡œ ë¶„í• í•˜ì—¬ CLIP ë¶„ì„
    if not yolo_detected:
        print("âš ï¸ YOLOê°€ ê°ì§€í•œ ì‹ì¬ë£Œ ì—†ìŒ, CLIPìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ ë¶„ì„...")

        for y in range(0, image_height, grid_size):
            for x in range(0, image_width, grid_size):
                x1 = x
                y1 = y
                x2 = min(x + grid_size, image_width)
                y2 = min(y + grid_size, image_height)

                grid_img = image.crop((x1, y1, x2, y2))

                image_input = preprocess(grid_img).unsqueeze(0).to(device)
                image_features = clip_model.encode_image(image_input).detach()
                similarity = (image_features @ text_features.T).softmax(dim=-1)

                for idx, conf in enumerate(similarity.squeeze(0).tolist()):
                    if conf >= 0.2:
                        detected_ingredients.add(possible_labels[idx])
                        print(f"âœ… CLIP ë¶„ì„ ê²°ê³¼: {possible_labels[idx]} (ìœ ì‚¬ë„ {conf:.2f})")

    # âœ… ê°ì§€ëœ ì¬ë£Œë¥¼ í•œê¸€ë¡œ ë³€í™˜
    translated_ingredients = [ingredient_translations.get(ing, ing) for ing in detected_ingredients]

    # âœ… ë³€í™˜ëœ ê°’ ë””ë²„ê¹… ë¡œê·¸
    print(f"ë³€í™˜ëœ ì¬ë£Œ ë¦¬ìŠ¤íŠ¸: {translated_ingredients}")

    return list(translated_ingredients)




### ì„ë² ë”© ëª¨ë¸
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# ëª¨ë¸
model = ChatOpenAI(model="gpt-4o-mini")

### ë©”ëª¨ë¦¬
memory = ConversationBufferMemory(llm=model, max_token_limit=200, return_messages=True, memory_key="history")

def load(case):
    if case == "fun":
        conn = sqlite3.connect("funs.db")
        df = pd.read_sql("SELECT * FROM menu", conn)

        df['page_content'] = df['name'] + " " + df['ingredients'] + " " + df['recipe']
        df.drop(columns=['name', 'ingredients', 'recipe'], inplace=True)
        conn.close()
        loader = DataFrameLoader(df, page_content_column="page_content")
        docs = loader.load()
        return docs
    
    elif case == "ref":
        conn = sqlite3.connect("fridges.db")
        df = pd.read_sql("SELECT * FROM menu", conn)

        df['page_content'] = df['name'] + " " + df['ingredients'] + " " + df['recipes']
        df.drop(columns=['name', 'ingredients', 'recipes'], inplace=True)
        conn.close()
        loader = DataFrameLoader(df, page_content_column="page_content")
        docs = loader.load()
        return docs
    
    else:
        conn = sqlite3.connect("data.db")
        df = pd.read_sql("SELECT * FROM processed_data", conn)

        df['page_content'] = df['name'] + " " + df['ingredients'] + " " + df['recipe'] + " " + df['category'] + " " + df['info'] + " " + df['intro']
        df.drop(columns=['name', 'ingredients', 'recipe', "info", "intro"], inplace=True)
        conn.close()
        loader = DataFrameLoader(df, page_content_column="page_content")
        docs = loader.load()
        return docs

def fun(query=None):
    '''
    í¸ìŠ¤í† ë‘ retriever
    '''
    ## load
    docs = load("fun")

    # ## vectordb ì €ì¥ -> ìµœì´ˆ ì¼íšŒë§Œ ì‹¤í–‰
    # fais = FAISS.from_documents(documents=docs, embedding=embeddings) # í¸ìŠ¤í† ë‘ ì„ë² ë”© í›„ db
    # fais.save_local("fun_faiss") # ë¡œì»¬ ì €ì¥
    
    ## vectordb ë¡œë“œ
    fais = FAISS.load_local("fun_faiss", embeddings, allow_dangerous_deserialization=True) # ë¡œì»¬ ì €ì¥ ë¡œë“œ

    ## bm25 retriever, faiss retriever ì•™ìƒë¸”
    bm25_retr = BM25Retriever.from_documents(docs)
    bm25_retr.k = 3
    fais_retr = fais.as_retriever(search_kwargs={"k": 3})
    return bm25_retr, fais_retr

def ref(query=None):
    '''
    ëƒ‰ì¥ê³ ë¥¼ ë¶€íƒí•´ retriever
    '''
    ## load
    docs = load("ref")

    # ## vectordb ì €ì¥ -> ìµœì´ˆ ì¼íšŒë§Œ ì‹¤í–‰
    # fais = FAISS.from_documents(documents=docs, embedding=embeddings) # ëƒ‰ë¶€ ì„ë² ë”© í›„ db
    # fais.save_local("ref_faiss") # ë¡œì»¬ ì €ì¥

    ## vectordb ë¡œë“œ
    fais = FAISS.load_local("ref_faiss", embeddings, allow_dangerous_deserialization=True)

    ## bm25 retriever, faiss retriever ì•™ìƒë¸”
    bm25_retr = BM25Retriever.from_documents(docs)
    bm25_retr.k = 3
    fais_retr = fais.as_retriever(search_kwargs={"k": 3})
    return bm25_retr, fais_retr

def man(query=None):
    '''
    ë§Œê°œì˜ ë ˆì‹œí”¼ retriever
    '''
    ## load
    docs = load("man")

    # ## vectordb ì €ì¥ -> ìµœì´ˆ ì¼íšŒë§Œ ì‹¤í–‰
    # fais = FAISS.from_documents(documents=docs, embedding=embeddings) # ë§Œê°œ ì„ë² ë”© í›„ db
    # fais.save_local("man_faiss") # ë¡œì»¬ ì €ì¥

    # vectordb ë¡œë“œ
    fais = FAISS.load_local("man_faiss", embeddings, allow_dangerous_deserialization=True)

    ## bm25 retriever, faiss retriever ì•™ìƒë¸”
    bm25_retr = BM25Retriever.from_documents(docs)
    bm25_retr.k = 3
    fais_retr = fais.as_retriever(search_kwargs={"k": 3})
    return bm25_retr, fais_retr





def mkch():
    retrievers = []
    for case in ["fun", "ref", "man"]:
        docs = load(case)
        fais = FAISS.load_local(f"{case}_faiss", embeddings, allow_dangerous_deserialization=True)
        bm25_retr = BM25Retriever.from_documents(docs)
        bm25_retr.k = 3
        fais_retr = fais.as_retriever(search_kwargs={"k": 3})
        retrievers.extend([bm25_retr, fais_retr])

    retriever = EnsembleRetriever(retrievers=retrievers)

    messages = [
        ("ai", """
        ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸(question)ì— ë§ëŠ” ìš”ë¦¬ ì„¸ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” aiì•¼.

        ìš”ë¦¬ ì†Œê°œí•  ë•Œ ì´ë¦„ì„ ì–¸ê¸‰í•œ ë’¤, í•œ ì¤„ ì •ë„ ê°„ë‹¨í•œ ìš”ë¦¬ ì†Œê°œë¥¼ í•˜ê³  ì¬ë£Œë¥¼ ì•Œë ¤ì¤˜.
        ì‚¬ìš©ìê°€ ë„¤ê°€ ì¶”ì²œí•´ì¤€ ìš”ë¦¬ ì•ˆì—ì„œ ìš”ë¦¬ë¥¼ ì„ íƒí•˜ë©´ ë ˆì‹œí”¼ì™€ í•¨ê»˜ í•´ë‹¹ ìš”ë¦¬ì˜ ì‚¬ì§„, ì˜ìƒ ë°ì´í„°ë¥¼ ì•Œë ¤ì¤˜.
        ë©”ë‰´ ì´ë¦„, ì¬ë£Œ, ë ˆì‹œí”¼, ì‚¬ì§„, ì˜ìƒì€ fun_faiss, man_faiss, ref_faissì— ìˆëŠ” ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€.
        ë§Œì•½ ì‚¬ì§„ í˜¹ì€ ì˜ìƒì´ ì—†ìœ¼ë©´, ì‚¬ì§„ì´ë‚˜ ì˜ìƒì€ ì•Œë ¤ì£¼ì§€ë§ˆ.
        ë‹µë³€ì„ contextì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•´.
        ë‹µë³€ìœ¼ë¡œ ìš”ë¦¬ ì„¸ê°€ì§€ë¥¼ ì•Œë ¤ì¤„ ë•ŒëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¬ë£Œê°€ ì •í™•íˆ ë“¤ì–´ê°„ ìˆœì„œëŒ€ë¡œ ë‹µë³€í•˜ê³ 
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¬ë£Œê°€ ì—¬ëŸ¬ê°€ì§€ë¼ë©´ ì…ë ¥ëœ ì¬ë£Œê°€ ë§ì€ ìš”ë¦¬ ìˆœì„œëŒ€ë¡œ ë‹µë³€í•´.
        ë§Œì•½ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¬ë£Œê°€ ë“¤ì–´ê°„ ìš”ë¦¬ê°€ ì—†ìœ¼ë©´ ê·¸ ìš”ë¦¬ëŠ” ì œì™¸í•˜ê³  ë‹µë³€í•´.
        {context}"""),
        MessagesPlaceholder(variable_name="history", optional=True),
        ("human", "{question}"),
    ]

    prompt_template = ChatPromptTemplate(messages)

    chain = RunnableLambda(lambda x: x['question']) | {
        "context": retriever,
        "question": RunnablePassthrough(),
        "history": RunnableLambda(lambda _: memory.load_memory_variables({})["history"])
    } | prompt_template | model | StrOutputParser()

    return chain


    # ë©”ëª¨ë¦¬
    def load_history(input):
        return memory.load_memory_variables({})["history"]

    # retriever ë¡œë“œ => ì¶”í›„ í•¨ìˆ˜ ì„ íƒ ì½”ë“œ ë„£ì–´ì•¼ í•¨
    rbm25_retr, rfais_retr = ref()
    fbm25_retr, ffais_retr = fun()
    mbm25_retr, mfais_retr = man()

    retriever = EnsembleRetriever(retrievers=[rbm25_retr, rfais_retr, fbm25_retr, ffais_retr,mbm25_retr, mfais_retr],) # weights=[0.25, 0.25, 0.25, 0.25],)

    # Chain êµ¬ì„± retriever(ê´€ë ¨ ë¬¸ì„œ ì¡°íšŒ) -> prompt_template(prompt ìƒì„±) model(ì •ë‹µ) -> output parser
    chain = RunnableLambda(lambda x:x['question']) | {"context": retriever, "question":RunnablePassthrough() , "history": RunnableLambda(load_history)}  | prompt_template | model | StrOutputParser()
    return chain



        
# âœ… ì±—ë´‡ ì‘ë‹µ ì‹œ í•œêµ­ì–´ë¡œ ë³€í™˜ëœ ì¬ë£Œ ë¦¬ìŠ¤íŠ¸ í•¨ê»˜ ì¶œë ¥
def chat():
    """ ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ë˜ëŠ” ì—¬ëŸ¬ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìš”ë¦¬ë¥¼ ì¶”ì²œí•˜ëŠ” í•¨ìˆ˜ """
    chain = mkch()

    while True:
        query = input("í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥ (ì—¬ëŸ¬ ê°œ ì…ë ¥ ì‹œ ë„ì–´ì“°ê¸°ë¡œ êµ¬ë¶„, ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥) > ")
        if query.lower() == "exit":
            break

        input_parts = query.split()
        detected_ingredients = set()
        text_input = []

        for part in input_parts:
            if os.path.exists(part) and part.lower().endswith((".jpg", ".jpeg", ".png")):
                print(f"ğŸ–¼ ì´ë¯¸ì§€ ê°ì§€ ì¤‘... ({part})")
                detected_ingredients.update(detect_ingredients(part))
            else:
                text_input.append(part)

        # âœ… ê°ì§€ëœ ì‹ì¬ë£Œ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ (í•œê¸€ ë³€í™˜ ì ìš©ë¨)
        if detected_ingredients:
            print("\nğŸ“Œ **ì¬ë£Œ ë¦¬ìŠ¤íŠ¸ (ë³´ì´ëŠ” ë²”ìœ„ ë‚´)**")
            for ingredient in detected_ingredients:
                print(f"âœ… {ingredient}")

        # âœ… ìµœì¢… Query êµ¬ì„± (ì´ë¯¸ì§€ì—ì„œ ê°ì§€ëœ ì¬ë£Œ + ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸)
        combined_query = " ".join(text_input)
        query_with_ingredients = f"{combined_query} ê°ì§€ëœ ì¬ë£Œ: {', '.join(detected_ingredients)}"

        print(f"Final Query: {query_with_ingredients}")

        res = chain.invoke({"question": query_with_ingredients})
        memory.save_context(inputs={"human": query_with_ingredients}, outputs={"ai": res})

        if detected_ingredients:
            print("\nğŸ“ ì¸ì‹ëœ ì¬ë£Œë“¤:")
            print(" / ".join(detected_ingredients))
            print("\nğŸ½ï¸ ì¶”ì²œ ìš”ë¦¬ ëª©ë¡:")

        print(res)

chat()




